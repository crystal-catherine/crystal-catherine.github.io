## 1. Uncertainty-Supervised Interpretable and Robust Evidential Segmentation
**Conference:** MICCAI 2025 Oral  
**Abstract:**  
> Uncertainty estimation has been widely studied in medical image segmentation as a tool to provide reliability, particularly in deep learning approaches.
However, previous methods generally lack effective supervision in uncertainty estimation, leading to low interpretability and robustness of the predictions. 
In this work, we propose a self-supervised approach to guide the learning of uncertainty.
Specifically, we introduce three principles about the relationships between the uncertainty and the image gradients around boundaries and noise.
Based on these principles, two uncertainty supervision losses are designed.
These losses enhance the alignment between model predictions and human interpretation. 
Accordingly, we introduce novel quantitative metrics for evaluating the interpretability and robustness of uncertainty. Experimental results demonstrate that compared to state-of-the-art approaches, the proposed method can achieve competitive segmentation performance and superior results in out-of-distribution (OOD) scenarios while significantly improving the interpretability and robustness of uncertainty estimation.

**Resources:**  
- ğŸ”— [Code on GitHub](https://github.com/suiannaius/SURE)  
- ğŸ“ <span style="color:gray;">PDF (coming soon)</span>


